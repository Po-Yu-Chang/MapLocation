# MapLocationApp 人臉辨識功能技術文件

## 專案概述

本文件詳述為 MapLocationApp (.NET MAUI 跨平台應用程式) 新增人臉辨識功能的完整實作方案。該功能將作為新的 Tab item 整合到現有應用程式中。

### 需求摘要

1. 新增人臉辨識 Tab item
2. 支援相機裝置選擇（手機前鏡頭、桌面鏡頭等）
3. 人臉儲存功能（例如：保存為 "Johnson"）
4. 即時人臉辨識和標記功能
5. 跨平台支援（Android、iOS、Windows、macOS）

## 技術挑戰與問題分析

### 主要技術挑戰

#### 1. FaceAiSharp 技術優勢與限制
**技術優勢：**
- 基於 ImageSharp 和 ONNX Runtime 的現代架構
- 使用 ArcFace 和 InsightFace SCRFD 等最新模型
- MIT 授權適合商業專案
- 支援硬體加速 (CPU/GPU)
- 統一的 .NET API 設計

**平台限制：**
- 主要針對桌面平台 (Windows/macOS/Linux) 優化
- 移動平台支援需要進一步評估
- ONNX Runtime 在移動裝置的性能考量

#### 2. .NET MAUI 相機存取限制
**問題描述：**
- MediaPicker API 無法指定前/後鏡頭選擇
- 預設行為因平台而異（iOS iPad 預設後鏡頭，其他通常是前鏡頭）

**解決方案：**
- 使用 CommunityToolkit.Maui.Camera 的 CameraView 獲得更好的相機控制
- 平台特定程式碼來處理相機選擇

#### 3. 跨平台人臉辨識技術選擇
**挑戰：**
- 不同平台最佳化的解決方案不同
- 統一 API 設計的複雜性

## 推薦技術架構

### 核心技術選擇

#### 主要技術選擇 - FaceAiSharp 統一解決方案
- **核心套件:** FaceAiSharp.Bundle (包含預訓練模型)
- **技術基礎:** ImageSharp + ONNX Runtime
- **模型技術:** ArcFace (人臉識別) + InsightFace SCRFD (人臉偵測)
- **相機存取:** CommunityToolkit.Maui.Camera
- **平台支援:** Windows, macOS, Linux (桌面優先)
- **優勢:** 
  - 最新的 ONNX 模型技術
  - MIT 授權適合商業使用
  - 硬體加速支援
  - 統一 API 設計

#### 移動平台整合策略
- **優先方案:** FaceAiSharp (如支援行動平台)
- **備用方案 Android:** Xamarin.Google.MLKit.FaceDetection
- **備用方案 iOS:** 原生 Apple Vision Framework 綁定
- **相機存取:** CommunityToolkit.Maui.Camera
- **注意事項:** FaceAiSharp 主要針對桌面平台優化，移動平台需要性能評估

### 架構設計

```
MapLocationApp
├── Views/
│   └── FaceRecognitionPage.xaml         # 人臉辨識主頁面
├── Services/
│   ├── IFaceRecognitionService.cs       # 人臉辨識服務介面
│   ├── FaceRecognitionService.cs        # 跨平台實作基礎
│   ├── Platform/
│   │   ├── Android/
│   │   │   └── AndroidFaceService.cs    # Android ML Kit 實作
│   │   ├── iOS/
│   │   │   └── iOSFaceService.cs        # iOS Vision 實作
│   │   ├── Desktop/
│   │   │   └── FaceAiSharpService.cs     # FaceAiSharp 統一實作
│   │   └── Mobile/
│   │       ├── AndroidMLKitService.cs    # Android ML Kit 備用
│   │       └── iOSVisionService.cs       # iOS Vision 備用
│   ├── ICameraService.cs                # 相機服務介面
│   └── CameraService.cs                 # 相機管理服務
├── Models/
│   ├── FaceData.cs                      # 人臉資料模型
│   ├── RecognitionResult.cs             # 辨識結果模型
│   └── CameraDevice.cs                  # 相機裝置模型
└── ViewModels/
    └── FaceRecognitionViewModel.cs      # 頁面 ViewModel
```

## 功能詳細設計

### 1. FaceAiSharp 服務介面詳細定義

```csharp
// 核心人臉辨識服務介面
public interface IFaceRecognitionService
{
    // 基本人臉偵測功能
    Task<List<FaceData>> DetectFacesAsync(byte[] imageData, CancellationToken cancellationToken = default);
    Task<List<FaceData>> DetectFacesAsync(Stream imageStream, CancellationToken cancellationToken = default);
    Task<List<FaceData>> DetectFacesAsync(string imagePath, CancellationToken cancellationToken = default);
    
    // 人臉辨識功能
    Task<RecognitionResult> RecognizeFaceAsync(byte[] imageData, CancellationToken cancellationToken = default);
    Task<RecognitionResult> RecognizeFaceAsync(Stream imageStream, CancellationToken cancellationToken = default);
    
    // 人臉資料管理
    Task<bool> SaveFaceAsync(FaceData faceData, string name, CancellationToken cancellationToken = default);
    Task<bool> UpdateFaceAsync(string existingName, FaceData newFaceData, CancellationToken cancellationToken = default);
    Task<bool> DeleteSavedFaceAsync(string name, CancellationToken cancellationToken = default);
    Task<List<string>> GetSavedFaceNamesAsync(CancellationToken cancellationToken = default);
    Task<FaceData?> GetSavedFaceAsync(string name, CancellationToken cancellationToken = default);
    
    // 進階功能
    Task<bool> TrainModelWithFacesAsync(List<(string name, FaceData faceData)> trainingData, CancellationToken cancellationToken = default);
    Task<float> GetFaceSimilarityAsync(FaceData face1, FaceData face2, CancellationToken cancellationToken = default);
    
    // 效能與設定
    Task<ServiceHealthStatus> GetHealthStatusAsync();
    Task<bool> OptimizePerformanceAsync(PerformanceSettings settings);
    
    // 事件
    event EventHandler<FaceDetectedEventArgs> FaceDetected;
    event EventHandler<FaceRecognizedEventArgs> FaceRecognized;
    event EventHandler<ServiceErrorEventArgs> ServiceError;
    
    // 屬性
    bool IsInitialized { get; }
    FaceAiSharpVersion Version { get; }
    SupportedFeatures SupportedFeatures { get; }
}

// 支援的功能列舉
[Flags]
public enum SupportedFeatures
{
    None = 0,
    FaceDetection = 1,
    FaceRecognition = 2,
    FacialLandmarks = 4,
    EyeStateDetection = 8,
    GpuAcceleration = 16,
    BatchProcessing = 32
}

// 服務健康狀態
public class ServiceHealthStatus
{
    public bool IsHealthy { get; set; }
    public string Status { get; set; } = string.Empty;
    public Dictionary<string, object> Metrics { get; set; } = new();
    public DateTime LastCheck { get; set; }
    public List<string> Warnings { get; set; } = new();
    public List<string> Errors { get; set; } = new();
}

// 效能設定
public class PerformanceSettings
{
    public bool EnableGpuAcceleration { get; set; } = true;
    public int MaxConcurrentOperations { get; set; } = Environment.ProcessorCount;
    public ModelPrecision ModelPrecision { get; set; } = ModelPrecision.Balanced;
    public int ImageResizeWidth { get; set; } = 640;
    public int ImageResizeHeight { get; set; } = 480;
    public bool EnableCaching { get; set; } = true;
    public int CacheMaxSize { get; set; } = 100;
}

public enum ModelPrecision
{
    Fast,      // 快速但較不精確
    Balanced,  // 平衡速度與精確度
    Accurate   // 最精確但較慢
}
```

### 2. 相機服務介面

```csharp
public interface ICameraService
{
    Task<List<CameraDevice>> GetAvailableCamerasAsync();
    Task<bool> SetActiveCameraAsync(CameraDevice camera);
    Task<byte[]> CapturePhotoAsync();
    bool IsSupported { get; }
}
```

### 3. FaceAiSharp 資料模型詳細定義

```csharp
// 人臉資料核心模型
public class FaceData
{
    public string Id { get; set; } = Guid.NewGuid().ToString();
    public string Name { get; set; } = string.Empty;
    public byte[] EncodedFace { get; set; } = Array.Empty<byte>();
    public Rectangle BoundingBox { get; set; }
    public DateTime CreatedAt { get; set; } = DateTime.UtcNow;
    public DateTime LastUpdated { get; set; } = DateTime.UtcNow;
    
    // FaceAiSharp 特定屬性
    public float[] FeatureVector { get; set; } = Array.Empty<float>();
    public FacialLandmarks? Landmarks { get; set; }
    public EyeState EyeState { get; set; } = EyeState.Unknown;
    public float Quality { get; set; } // 0-1，影像品質評分
    public FaceAttributes Attributes { get; set; } = new();
    
    // 中繼資料
    public Dictionary<string, object> Metadata { get; set; } = new();
    public int Version { get; set; } = 1;
    public string ModelVersion { get; set; } = string.Empty;
}

// 辨識結果
public class RecognitionResult
{
    public List<DetectedFace> DetectedFaces { get; set; } = new();
    public TimeSpan ProcessingTime { get; set; }
    public string ModelUsed { get; set; } = string.Empty;
    public Dictionary<string, object> Metrics { get; set; } = new();
    
    public bool HasFaces => DetectedFaces.Count > 0;
    public int FaceCount => DetectedFaces.Count;
}

// 偵測到的人臉
public class DetectedFace
{
    public string Name { get; set; } = string.Empty;
    public Rectangle BoundingBox { get; set; }
    public float Confidence { get; set; }
    public FacialLandmarks? Landmarks { get; set; }
    public EyeState EyeState { get; set; } = EyeState.Unknown;
    public FaceAttributes Attributes { get; set; } = new();
    
    public bool IsUnknown => string.IsNullOrEmpty(Name);
    public bool IsHighConfidence => Confidence >= 0.8f;
    public bool IsMediumConfidence => Confidence >= 0.6f && Confidence < 0.8f;
    public bool IsLowConfidence => Confidence < 0.6f;
}

// 臉部特徵點
public class FacialLandmarks
{
    public Point LeftEye { get; set; }
    public Point RightEye { get; set; }
    public Point Nose { get; set; }
    public Point LeftMouthCorner { get; set; }
    public Point RightMouthCorner { get; set; }
    
    // 額外的 68 個特徵點 (可選)
    public List<Point>? AllLandmarks { get; set; }
    
    public float GetEyeDistance() 
    {
        var dx = LeftEye.X - RightEye.X;
        var dy = LeftEye.Y - RightEye.Y;
        return (float)Math.Sqrt(dx * dx + dy * dy);
    }
}

// 眼睛狀態
public enum EyeState
{
    Unknown,
    Open,
    Closed,
    LeftOpen,
    RightOpen,
    LeftClosed,
    RightClosed
}

// 人臉屬性
public class FaceAttributes
{
    public Gender Gender { get; set; } = Gender.Unknown;
    public AgeRange EstimatedAge { get; set; } = new();
    public Emotion DominantEmotion { get; set; } = Emotion.Unknown;
    public float EmotionConfidence { get; set; }
    public bool WearingGlasses { get; set; }
    public bool WearingMask { get; set; }
    public float HeadPose { get; set; } // 頭部角度
}

public enum Gender { Unknown, Male, Female }

public class AgeRange
{
    public int Min { get; set; } = 0;
    public int Max { get; set; } = 100;
    public int Estimated => (Min + Max) / 2;
}

public enum Emotion
{
    Unknown,
    Happy,
    Sad,
    Angry,
    Fear,
    Surprise,
    Disgust,
    Neutral
}

// 相機裝置
public class CameraDevice
{
    public string Id { get; set; } = string.Empty;
    public string Name { get; set; } = string.Empty;
    public string Description { get; set; } = string.Empty;
    public CameraType Type { get; set; } = CameraType.Unknown;
    public bool IsAvailable { get; set; }
    public bool IsDefault { get; set; }
    
    // 技術規格
    public List<CameraResolution> SupportedResolutions { get; set; } = new();
    public List<int> SupportedFrameRates { get; set; } = new();
    public CameraCapabilities Capabilities { get; set; } = new();
    
    public override string ToString() => $"{Name} ({Type})";
}

public enum CameraType
{
    Unknown,
    Front,      // 前鏡頭
    Back,       // 後鏡頭
    External,   // 外部攝影機
    USB,        // USB 攝影機
    Network     // 網路攝影機
}

public class CameraResolution
{
    public int Width { get; set; }
    public int Height { get; set; }
    public override string ToString() => $"{Width}x{Height}";
}

public class CameraCapabilities
{
    public bool SupportsAutoFocus { get; set; }
    public bool SupportsFlash { get; set; }
    public bool SupportsZoom { get; set; }
    public bool SupportsHDR { get; set; }
}

// 事件參數
public class FaceDetectedEventArgs : EventArgs
{
    public List<DetectedFace> Faces { get; }
    public TimeSpan ProcessingTime { get; }
    public DateTime Timestamp { get; }
    
    public FaceDetectedEventArgs(List<DetectedFace> faces, TimeSpan processingTime)
    {
        Faces = faces;
        ProcessingTime = processingTime;
        Timestamp = DateTime.UtcNow;
    }
}

public class FaceRecognizedEventArgs : EventArgs
{
    public DetectedFace RecognizedFace { get; }
    public bool IsNewFace { get; }
    public DateTime Timestamp { get; }
    
    public FaceRecognizedEventArgs(DetectedFace face, bool isNewFace)
    {
        RecognizedFace = face;
        IsNewFace = isNewFace;
        Timestamp = DateTime.UtcNow;
    }
}

public class ServiceErrorEventArgs : EventArgs
{
    public Exception Exception { get; }
    public string ErrorMessage { get; }
    public ErrorSeverity Severity { get; }
    public DateTime Timestamp { get; }
    
    public ServiceErrorEventArgs(Exception exception, ErrorSeverity severity)
    {
        Exception = exception;
        ErrorMessage = exception.Message;
        Severity = severity;
        Timestamp = DateTime.UtcNow;
    }
}

public enum ErrorSeverity
{
    Info,
    Warning,
    Error,
    Critical
}

// FaceAiSharp 版本資訊
public class FaceAiSharpVersion
{
    public string Version { get; set; } = string.Empty;
    public string OnnxRuntimeVersion { get; set; } = string.Empty;
    public string ImageSharpVersion { get; set; } = string.Empty;
    public DateTime BuildDate { get; set; }
    public List<string> SupportedModels { get; set; } = new();
}
```

## 4. FaceAiSharp 具體實作範例

### 4.1. FaceAiSharp 服務實作

```csharp
using FaceAiSharp;
using SixLabors.ImageSharp;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;

public class FaceAiSharpService : IFaceRecognitionService, IDisposable
{
    private readonly ILogger<FaceAiSharpService> _logger;
    private readonly IFaceDatabase _database;
    private readonly FaceAiSharpOptions _options;
    private readonly SemaphoreSlim _semaphore;
    
    private FaceDetector? _detector;
    private FaceRecognizer? _recognizer;
    private EyeStateDetector? _eyeDetector;
    
    private bool _disposed;
    private readonly ConcurrentDictionary<string, FaceData> _faceCache = new();
    
    public event EventHandler<FaceDetectedEventArgs>? FaceDetected;
    public event EventHandler<FaceRecognizedEventArgs>? FaceRecognized;
    public event EventHandler<ServiceErrorEventArgs>? ServiceError;
    
    public bool IsInitialized { get; private set; }
    public FaceAiSharpVersion Version { get; private set; } = new();
    public SupportedFeatures SupportedFeatures { get; private set; }

    public FaceAiSharpService(
        ILogger<FaceAiSharpService> logger,
        IFaceDatabase database,
        IOptions<FaceAiSharpOptions> options)
    {
        _logger = logger;
        _database = database;
        _options = options.Value;
        _semaphore = new SemaphoreSlim(_options.MaxConcurrentOperations);
        
        InitializeAsync().ConfigureAwait(false);
    }

    private async Task InitializeAsync()
    {
        try
        {
            _logger.LogInformation("正在初始化 FaceAiSharp 服務...");
            
            // 初始化 ONNX Runtime Provider
            var sessionOptions = new Microsoft.ML.OnnxRuntime.SessionOptions();
            if (_options.EnableGpuAcceleration && IsGpuAvailable())
            {
                sessionOptions.AppendExecutionProvider_CUDA();
                _logger.LogInformation("已啟用 GPU 加速");
            }
            else
            {
                sessionOptions.AppendExecutionProvider_CPU();
                _logger.LogInformation("使用 CPU 推理");
            }
            
            // 載入模型
            _detector = FaceDetector.Create(_options.DetectionModelPath, sessionOptions);
            _recognizer = FaceRecognizer.Create(_options.RecognitionModelPath, sessionOptions);
            
            if (_options.EnableEyeStateDetection)
            {
                _eyeDetector = EyeStateDetector.Create(_options.EyeStateModelPath, sessionOptions);
            }
            
            // 設定支持的功能
            SupportedFeatures = SupportedFeatures.FaceDetection | SupportedFeatures.FaceRecognition;
            if (_eyeDetector != null)
                SupportedFeatures |= SupportedFeatures.EyeStateDetection;
            if (_options.EnableGpuAcceleration && IsGpuAvailable())
                SupportedFeatures |= SupportedFeatures.GpuAcceleration;
            
            // 載入版本資訊
            Version = new FaceAiSharpVersion
            {
                Version = typeof(FaceDetector).Assembly.GetName().Version?.ToString() ?? "Unknown",
                OnnxRuntimeVersion = Microsoft.ML.OnnxRuntime.OrtEnv.Instance().GetVersionString(),
                ImageSharpVersion = typeof(Image).Assembly.GetName().Version?.ToString() ?? "Unknown",
                BuildDate = DateTime.UtcNow,
                SupportedModels = new List<string> { "SCRFD", "ArcFace", "OpenClosedEye" }
            };
            
            // 預載已儲存的人臉
            await LoadSavedFacesAsync();
            
            IsInitialized = true;
            _logger.LogInformation("FaceAiSharp 服務初始化完成");
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "FaceAiSharp 服務初始化失敗");
            OnServiceError(ex, ErrorSeverity.Critical);
            throw;
        }
    }

    public async Task<List<FaceData>> DetectFacesAsync(byte[] imageData, CancellationToken cancellationToken = default)
    {
        if (!IsInitialized || _detector == null)
            throw new InvalidOperationException("服務尚未初始化");

        await _semaphore.WaitAsync(cancellationToken);
        try
        {
            var stopwatch = Stopwatch.StartNew();
            
            using var image = Image.Load(imageData);
            var faces = new List<FaceData>();
            
            // 調整影像大小以提升性能
            if (image.Width > _options.MaxImageWidth || image.Height > _options.MaxImageHeight)
            {
                var scale = Math.Min(
                    (float)_options.MaxImageWidth / image.Width,
                    (float)_options.MaxImageHeight / image.Height
                );
                
                var newWidth = (int)(image.Width * scale);
                var newHeight = (int)(image.Height * scale);
                
                image.Mutate(x => x.Resize(newWidth, newHeight));
            }
            
            // 偵測人臉
            var detections = _detector.DetectFaces(image);
            
            foreach (var detection in detections)
            {
                var faceData = new FaceData
                {
                    Id = Guid.NewGuid().ToString(),
                    BoundingBox = new Rectangle(
                        (int)detection.Box.X,
                        (int)detection.Box.Y,
                        (int)detection.Box.Width,
                        (int)detection.Box.Height
                    ),
                    Quality = detection.Confidence,
                    CreatedAt = DateTime.UtcNow
                };
                
                // 提取特徵點
                if (detection.Landmarks.Length >= 5)
                {
                    faceData.Landmarks = new FacialLandmarks
                    {
                        LeftEye = new Point((int)detection.Landmarks[0].X, (int)detection.Landmarks[0].Y),
                        RightEye = new Point((int)detection.Landmarks[1].X, (int)detection.Landmarks[1].Y),
                        Nose = new Point((int)detection.Landmarks[2].X, (int)detection.Landmarks[2].Y),
                        LeftMouthCorner = new Point((int)detection.Landmarks[3].X, (int)detection.Landmarks[3].Y),
                        RightMouthCorner = new Point((int)detection.Landmarks[4].X, (int)detection.Landmarks[4].Y)
                    };
                }
                
                // 檢測眼睛狀態
                if (_eyeDetector != null && faceData.Landmarks != null)
                {
                    try
                    {
                        var eyeState = _eyeDetector.DetectEyeState(image, detection);
                        faceData.EyeState = ConvertEyeState(eyeState);
                    }
                    catch (Exception ex)
                    {
                        _logger.LogWarning(ex, "眼睛狀態檢測失敗");
                    }
                }
                
                faces.Add(faceData);
            }
            
            stopwatch.Stop();
            
            // 觸發事件
            var detectedFaces = faces.Select(f => new DetectedFace
            {
                BoundingBox = f.BoundingBox,
                Confidence = f.Quality,
                Landmarks = f.Landmarks,
                EyeState = f.EyeState
            }).ToList();
            
            OnFaceDetected(detectedFaces, stopwatch.Elapsed);
            
            return faces;
        }
        finally
        {
            _semaphore.Release();
        }
    }

    public async Task<RecognitionResult> RecognizeFaceAsync(byte[] imageData, CancellationToken cancellationToken = default)
    {
        if (!IsInitialized || _detector == null || _recognizer == null)
            throw new InvalidOperationException("服務尚未初始化");

        var stopwatch = Stopwatch.StartNew();
        var result = new RecognitionResult
        {
            ModelUsed = "FaceAiSharp",
            Metrics = new Dictionary<string, object>()
        };

        try
        {
            // 首先偵測人臉
            var detectedFaces = await DetectFacesAsync(imageData, cancellationToken);
            
            if (!detectedFaces.Any())
            {
                result.ProcessingTime = stopwatch.Elapsed;
                return result;
            }

            using var image = Image.Load(imageData);
            
            foreach (var faceData in detectedFaces)
            {
                // 提取人臉特徵向量
                var faceImage = ExtractFaceFromImage(image, faceData.BoundingBox);
                var embedding = _recognizer.GetEmbedding(faceImage);
                faceData.FeatureVector = embedding.ToArray();
                
                // 與已知人臉比對
                var bestMatch = await FindBestMatchAsync(embedding, cancellationToken);
                
                var detectedFace = new DetectedFace
                {
                    BoundingBox = faceData.BoundingBox,
                    Confidence = bestMatch?.Confidence ?? 0f,
                    Name = bestMatch?.Name ?? string.Empty,
                    Landmarks = faceData.Landmarks,
                    EyeState = faceData.EyeState
                };
                
                result.DetectedFaces.Add(detectedFace);
                
                // 觸發辨識事件
                OnFaceRecognized(detectedFace, bestMatch == null);
            }
            
            result.ProcessingTime = stopwatch.Elapsed;
            result.Metrics["face_count"] = result.DetectedFaces.Count;
            result.Metrics["processing_time_ms"] = result.ProcessingTime.TotalMilliseconds;
            
            return result;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "人臉辨識處理失敗");
            OnServiceError(ex, ErrorSeverity.Error);
            throw;
        }
    }

    public async Task<bool> SaveFaceAsync(FaceData faceData, string name, CancellationToken cancellationToken = default)
    {
        if (!IsInitialized)
            throw new InvalidOperationException("服務尚未初始化");

        try
        {
            // 檢查是否已存在同名人臉
            var existingFace = await _database.GetFaceByNameAsync(name, cancellationToken);
            if (existingFace != null)
            {
                _logger.LogWarning("嘗試儲存重複名稱的人臉: {Name}", name);
                return false;
            }
            
            faceData.Name = name;
            faceData.LastUpdated = DateTime.UtcNow;
            
            // 儲存到資料庫
            await _database.SaveFaceAsync(faceData, cancellationToken);
            
            // 更新記憶體快取
            _faceCache.TryAdd(name, faceData);
            
            _logger.LogInformation("已儲存人臉: {Name}", name);
            return true;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "儲存人臉失敗: {Name}", name);
            OnServiceError(ex, ErrorSeverity.Error);
            return false;
        }
    }

    private async Task<FaceMatch?> FindBestMatchAsync(ReadOnlyMemory<float> embedding, CancellationToken cancellationToken)
    {
        if (!_faceCache.Any())
            return null;

        FaceMatch? bestMatch = null;
        var bestSimilarity = 0f;

        foreach (var kvp in _faceCache)
        {
            var similarity = CalculateCosineSimilarity(embedding.Span, kvp.Value.FeatureVector);
            
            if (similarity > bestSimilarity && similarity >= _options.RecognitionThreshold)
            {
                bestSimilarity = similarity;
                bestMatch = new FaceMatch
                {
                    Name = kvp.Key,
                    Confidence = similarity,
                    FaceData = kvp.Value
                };
            }
        }

        return bestMatch;
    }

    private static float CalculateCosineSimilarity(ReadOnlySpan<float> a, ReadOnlySpan<float> b)
    {
        if (a.Length != b.Length)
            return 0f;

        var dotProduct = 0f;
        var normA = 0f;
        var normB = 0f;

        for (var i = 0; i < a.Length; i++)
        {
            dotProduct += a[i] * b[i];
            normA += a[i] * a[i];
            normB += b[i] * b[i];
        }

        return dotProduct / (MathF.Sqrt(normA) * MathF.Sqrt(normB));
    }

    // 事件觸發方法
    private void OnFaceDetected(List<DetectedFace> faces, TimeSpan processingTime)
    {
        FaceDetected?.Invoke(this, new FaceDetectedEventArgs(faces, processingTime));
    }

    private void OnFaceRecognized(DetectedFace face, bool isNewFace)
    {
        FaceRecognized?.Invoke(this, new FaceRecognizedEventArgs(face, isNewFace));
    }

    private void OnServiceError(Exception exception, ErrorSeverity severity)
    {
        ServiceError?.Invoke(this, new ServiceErrorEventArgs(exception, severity));
    }

    public void Dispose()
    {
        if (_disposed)
            return;

        _detector?.Dispose();
        _recognizer?.Dispose();
        _eyeDetector?.Dispose();
        _semaphore?.Dispose();

        _disposed = true;
    }
}

// 配置選項
public class FaceAiSharpOptions
{
    public string DetectionModelPath { get; set; } = "models/scrfd_10g_bnkps.onnx";
    public string RecognitionModelPath { get; set; } = "models/arcfaceresnet100-8.onnx";
    public string EyeStateModelPath { get; set; } = "models/open-closed-eye-0001.onnx";
    
    public bool EnableGpuAcceleration { get; set; } = true;
    public bool EnableEyeStateDetection { get; set; } = true;
    public int MaxConcurrentOperations { get; set; } = Environment.ProcessorCount;
    public int MaxImageWidth { get; set; } = 1280;
    public int MaxImageHeight { get; set; } = 720;
    public float RecognitionThreshold { get; set; } = 0.6f;
}

// 輔助類別
public class FaceMatch
{
    public string Name { get; set; } = string.Empty;
    public float Confidence { get; set; }
    public FaceData FaceData { get; set; } = new();
}
```

### 4.2. 資料庫介面實作

```csharp
public interface IFaceDatabase
{
    Task<FaceData?> GetFaceByNameAsync(string name, CancellationToken cancellationToken = default);
    Task<List<FaceData>> GetAllFacesAsync(CancellationToken cancellationToken = default);
    Task<bool> SaveFaceAsync(FaceData faceData, CancellationToken cancellationToken = default);
    Task<bool> UpdateFaceAsync(FaceData faceData, CancellationToken cancellationToken = default);
    Task<bool> DeleteFaceAsync(string name, CancellationToken cancellationToken = default);
    Task<int> GetFaceCountAsync(CancellationToken cancellationToken = default);
}

public class SQLiteFaceDatabase : IFaceDatabase
{
    private readonly string _connectionString;
    private readonly ILogger<SQLiteFaceDatabase> _logger;

    public SQLiteFaceDatabase(string connectionString, ILogger<SQLiteFaceDatabase> logger)
    {
        _connectionString = connectionString;
        _logger = logger;
        InitializeDatabase();
    }

    private void InitializeDatabase()
    {
        using var connection = new SqliteConnection(_connectionString);
        connection.Open();

        var createTableCmd = connection.CreateCommand();
        createTableCmd.CommandText = @"
            CREATE TABLE IF NOT EXISTS Faces (
                Id TEXT PRIMARY KEY,
                Name TEXT UNIQUE NOT NULL,
                EncodedFace BLOB,
                FeatureVector BLOB NOT NULL,
                BoundingBox TEXT,
                Landmarks TEXT,
                EyeState INTEGER,
                Quality REAL,
                Attributes TEXT,
                Metadata TEXT,
                CreatedAt TEXT NOT NULL,
                LastUpdated TEXT NOT NULL,
                Version INTEGER DEFAULT 1,
                ModelVersion TEXT
            )";
        createTableCmd.ExecuteNonQuery();

        // 建立索引
        var createIndexCmd = connection.CreateCommand();
        createIndexCmd.CommandText = "CREATE INDEX IF NOT EXISTS IX_Faces_Name ON Faces(Name)";
        createIndexCmd.ExecuteNonQuery();
    }

    public async Task<bool> SaveFaceAsync(FaceData faceData, CancellationToken cancellationToken = default)
    {
        try
        {
            using var connection = new SqliteConnection(_connectionString);
            await connection.OpenAsync(cancellationToken);

            using var command = connection.CreateCommand();
            command.CommandText = @"
                INSERT OR REPLACE INTO Faces 
                (Id, Name, EncodedFace, FeatureVector, BoundingBox, Landmarks, EyeState, Quality, 
                 Attributes, Metadata, CreatedAt, LastUpdated, Version, ModelVersion)
                VALUES 
                (@Id, @Name, @EncodedFace, @FeatureVector, @BoundingBox, @Landmarks, @EyeState, @Quality,
                 @Attributes, @Metadata, @CreatedAt, @LastUpdated, @Version, @ModelVersion)";

            command.Parameters.AddWithValue("@Id", faceData.Id);
            command.Parameters.AddWithValue("@Name", faceData.Name);
            command.Parameters.AddWithValue("@EncodedFace", faceData.EncodedFace);
            command.Parameters.AddWithValue("@FeatureVector", SerializeFloatArray(faceData.FeatureVector));
            command.Parameters.AddWithValue("@BoundingBox", JsonSerializer.Serialize(faceData.BoundingBox));
            command.Parameters.AddWithValue("@Landmarks", faceData.Landmarks != null ? JsonSerializer.Serialize(faceData.Landmarks) : DBNull.Value);
            command.Parameters.AddWithValue("@EyeState", (int)faceData.EyeState);
            command.Parameters.AddWithValue("@Quality", faceData.Quality);
            command.Parameters.AddWithValue("@Attributes", JsonSerializer.Serialize(faceData.Attributes));
            command.Parameters.AddWithValue("@Metadata", JsonSerializer.Serialize(faceData.Metadata));
            command.Parameters.AddWithValue("@CreatedAt", faceData.CreatedAt.ToString("O"));
            command.Parameters.AddWithValue("@LastUpdated", faceData.LastUpdated.ToString("O"));
            command.Parameters.AddWithValue("@Version", faceData.Version);
            command.Parameters.AddWithValue("@ModelVersion", faceData.ModelVersion);

            var result = await command.ExecuteNonQueryAsync(cancellationToken);
            return result > 0;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "儲存人臉資料失敗: {Name}", faceData.Name);
            throw;
        }
    }
}
```

## 實作計劃

### Phase 1: 基礎架構設置
1. 新增 NuGet 套件依賴
   ```xml
   <!-- 共用 -->
   <PackageReference Include="CommunityToolkit.Maui.Camera" />
   
   <!-- 桌面平台 -->
   <PackageReference Include="FaceAiSharp" Condition="'$(TargetFramework)' == 'net9.0-windows10.0.19041.0'" />
   
   <!-- Android -->
   <PackageReference Include="Xamarin.Google.MLKit.FaceDetection" Condition="'$(TargetFramework)' == 'net9.0-android'" />
   ```

2. 建立服務介面和基礎架構
3. 設定 Dependency Injection

### Phase 2: UI 實作
1. 新增 FaceRecognitionPage.xaml 頁面
2. 整合 CameraView 控制元件
3. 設計人臉框選和標記 UI
4. 實作相機切換功能

### Phase 3: FaceAiSharp 核心實作
1. 實作 FaceAiSharpService (統一桌面解決方案)
2. 整合 FaceAiSharp.Bundle 預訓練模型
3. 實作硬體加速選項
4. 備用移動平台服務 (AndroidMLKitService, iOSVisionService)
5. 平台適配和性能調優

### Phase 4: 資料持久化
1. 設計本地儲存結構 (SQLite)
2. 實作人臉資料的增刪改查
3. 加密敏感的人臉編碼資料

### Phase 5: 整合測試
1. 跨平台功能測試
2. 效能優化
3. 錯誤處理完善

## 預期挑戰與解決方案

### 1. FaceAiSharp 效能優化
**優化策略：**
- **ONNX Runtime 加速:** 啟用 CPU/GPU 硬體加速
- **模型選擇:** 根據裝置性能選擇輕量或精確模型
- **影像預處理:** ImageSharp 優化的影像處理管線
- **內存管理:** 使用 ArrayPool 和 IDisposable 模式
- **運算平行:** 多人臉同時處理支持

### 2. 記憶體管理
**挑戰：** 大量影像資料處理
**解決方案：**
- 及時釋放未使用的影像資料
- 使用記憶體快取策略
- 實作弱引用模式

### 3. FaceAiSharp 隱私安全優勢
**安全特性：**
- **完全本地化:** FaceAiSharp 不需網路連線，所有處理在本地完成
- **ONNX 模型安全:** 使用公開源碼的預訓練模型，無隱藏后門
- **數據不離境:** 人臉特徵數據不離開裝置
- **MIT 授權:** 开源透明，無商業限制
- **加密儲存:** 結合 SQLite 加密儲存生物特徵

### 4. 跨平台一致性
**挑戰：** 不同平台的 API 差異
**解決方案：**
- 統一的服務介面設計
- 平台特定的適配器模式
- 詳細的單元測試

## FaceAiSharp 整合的 NuGet 套件架構

### 核心依賴套件
```xml
<!-- 跨平台基礎套件 -->
<PackageReference Include="CommunityToolkit.Maui.Camera" Version="1.0.4" />
<PackageReference Include="sqlite-net-pcl" Version="1.9.172" />

<!-- FaceAiSharp 相關依賴 -->
<PackageReference Include="SixLabors.ImageSharp" Version="3.1.5" />
<PackageReference Include="Microsoft.ML.OnnxRuntime" Version="1.19.2" />
```

### FaceAiSharp 主要套件 (推薦配置)
```xml
<!-- 方案 A: Bundle 套件 (包含所有預訓練模型) -->
<PackageReference Include="FaceAiSharp.Bundle" Version="0.5.23" 
                  Condition="'$(TargetFramework)' == 'net9.0-windows10.0.19041.0' OR '$(TargetFramework)' == 'net9.0-macos'" />

<!-- 方案 B: 基礎套件 (自定義模型) -->
<PackageReference Include="FaceAiSharp" Version="0.5.23" 
                  Condition="'$(TargetFramework)' == 'net9.0-windows10.0.19041.0' OR '$(TargetFramework)' == 'net9.0-macos'" />
```

### 移動平台備用方案
```xml
<!-- Android ML Kit (如 FaceAiSharp 不支持) -->
<PackageReference Include="Xamarin.Google.MLKit.FaceDetection" Version="116.1.7.5" 
                  Condition="'$(TargetFramework)' == 'net9.0-android'" />

<!-- iOS Vision Framework 使用原生 API，無需 NuGet -->
```

### 性能優化套件
```xml
<!-- GPU 加速 (可選) -->
<PackageReference Include="Microsoft.ML.OnnxRuntime.Gpu" Version="1.19.2" 
                  Condition="'$(EnableGpuAcceleration)' == 'true'" />

<!-- DirectML 支持 Windows (可選) -->
<PackageReference Include="Microsoft.ML.OnnxRuntime.DirectML" Version="1.19.2" 
                  Condition="'$(TargetFramework)' == 'net9.0-windows10.0.19041.0' AND '$(EnableDirectML)' == 'true'" />
```

## 權限要求

### Android (Platforms/Android/AndroidManifest.xml)
```xml
<uses-permission android:name="android.permission.CAMERA" />
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" android:maxSdkVersion="32" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" android:maxSdkVersion="32" />
```

### iOS (Platforms/iOS/Info.plist)
```xml
<key>NSCameraUsageDescription</key>
<string>此應用程式需要存取相機以進行人臉辨識功能</string>
<key>NSPhotoLibraryUsageDescription</key>
<string>此應用程式需要存取照片庫以儲存辨識結果</string>
```

## 安全性考量

1. **資料加密:** 使用 AES 加密儲存人臉編碼資料
2. **存取控制:** 實作 PIN 碼或生物辨識保護
3. **資料最小化:** 只儲存必要的人臉特徵編碼，不儲存原始影像
4. **透明度:** 明確告知使用者資料使用方式
5. **資料主權:** 提供完整的資料刪除功能

## 5. 完整測試策略與實作指南

### 5.1. 單元測試詳細規劃

```csharp
// FaceAiSharp 服務單元測試
[TestFixture]
public class FaceAiSharpServiceTests
{
    private Mock<ILogger<FaceAiSharpService>> _mockLogger;
    private Mock<IFaceDatabase> _mockDatabase;
    private Mock<IOptions<FaceAiSharpOptions>> _mockOptions;
    private FaceAiSharpService _service;
    private FaceAiSharpOptions _testOptions;

    [SetUp]
    public void Setup()
    {
        _mockLogger = new Mock<ILogger<FaceAiSharpService>>();
        _mockDatabase = new Mock<IFaceDatabase>();
        _mockOptions = new Mock<IOptions<FaceAiSharpOptions>>();
        
        _testOptions = new FaceAiSharpOptions
        {
            DetectionModelPath = "test/models/scrfd.onnx",
            RecognitionModelPath = "test/models/arcface.onnx",
            EnableGpuAcceleration = false, // 測試環境使用 CPU
            RecognitionThreshold = 0.6f,
            MaxConcurrentOperations = 2
        };
        
        _mockOptions.Setup(o => o.Value).Returns(_testOptions);
        _service = new FaceAiSharpService(_mockLogger.Object, _mockDatabase.Object, _mockOptions.Object);
    }

    [Test]
    [Category("Core")]
    public async Task DetectFacesAsync_WithValidImage_ShouldReturnFaces()
    {
        // Arrange
        var testImageBytes = LoadTestImage("test_face_single.jpg");
        
        // Act
        var result = await _service.DetectFacesAsync(testImageBytes);
        
        // Assert
        Assert.That(result, Is.Not.Null);
        Assert.That(result.Count, Is.GreaterThan(0));
        Assert.That(result[0].BoundingBox, Is.Not.EqualTo(Rectangle.Empty));
        Assert.That(result[0].Quality, Is.InRange(0f, 1f));
        Assert.That(result[0].Id, Is.Not.Empty);
    }

    [Test]
    [Category("Core")]
    public async Task DetectFacesAsync_WithNoFaces_ShouldReturnEmptyList()
    {
        // Arrange
        var testImageBytes = LoadTestImage("no_faces.jpg");
        
        // Act
        var result = await _service.DetectFacesAsync(testImageBytes);
        
        // Assert
        Assert.That(result, Is.Not.Null);
        Assert.That(result.Count, Is.EqualTo(0));
    }

    [Test]
    [Category("Core")]
    public async Task RecognizeFaceAsync_WithKnownFace_ShouldReturnCorrectName()
    {
        // Arrange
        var testImageBytes = LoadTestImage("john_doe.jpg");
        var knownFace = CreateTestFaceData("John Doe", testImageBytes);
        
        _mockDatabase.Setup(db => db.GetAllFacesAsync(It.IsAny<CancellationToken>()))
                    .ReturnsAsync(new List<FaceData> { knownFace });
        
        // Act
        var result = await _service.RecognizeFaceAsync(testImageBytes);
        
        // Assert
        Assert.That(result.DetectedFaces.Count, Is.GreaterThan(0));
        Assert.That(result.DetectedFaces[0].Name, Is.EqualTo("John Doe"));
        Assert.That(result.DetectedFaces[0].Confidence, Is.GreaterThan(0.6f));
    }

    [Test]
    [Category("Performance")]
    public async Task DetectFacesAsync_Performance_ShouldCompleteWithinTimeLimit()
    {
        // Arrange
        var testImageBytes = LoadTestImage("test_face_multiple.jpg");
        var stopwatch = Stopwatch.StartNew();
        
        // Act
        await _service.DetectFacesAsync(testImageBytes);
        stopwatch.Stop();
        
        // Assert
        Assert.That(stopwatch.ElapsedMilliseconds, Is.LessThan(5000), "偵測應在 5 秒內完成");
    }

    [Test]
    [Category("Threading")]
    public async Task ConcurrentDetection_ShouldHandleMultipleRequests()
    {
        // Arrange
        var testImageBytes = LoadTestImage("test_face_single.jpg");
        var tasks = new List<Task<List<FaceData>>>();
        
        // Act
        for (int i = 0; i < 10; i++)
        {
            tasks.Add(_service.DetectFacesAsync(testImageBytes));
        }
        
        var results = await Task.WhenAll(tasks);
        
        // Assert
        Assert.That(results.Length, Is.EqualTo(10));
        Assert.That(results.All(r => r != null), Is.True);
    }

    [Test]
    [Category("Error")]
    public void DetectFacesAsync_WithInvalidImage_ShouldThrowException()
    {
        // Arrange
        var invalidImageBytes = new byte[] { 1, 2, 3, 4, 5 };
        
        // Act & Assert
        Assert.ThrowsAsync<InvalidDataException>(
            () => _service.DetectFacesAsync(invalidImageBytes));
    }

    [Test]
    [Category("Database")]
    public async Task SaveFaceAsync_WithValidData_ShouldReturnTrue()
    {
        // Arrange
        var faceData = CreateTestFaceData("Test Person", LoadTestImage("test_face_single.jpg"));
        
        _mockDatabase.Setup(db => db.GetFaceByNameAsync("Test Person", It.IsAny<CancellationToken>()))
                    .ReturnsAsync((FaceData?)null);
        _mockDatabase.Setup(db => db.SaveFaceAsync(It.IsAny<FaceData>(), It.IsAny<CancellationToken>()))
                    .ReturnsAsync(true);
        
        // Act
        var result = await _service.SaveFaceAsync(faceData, "Test Person");
        
        // Assert
        Assert.That(result, Is.True);
        _mockDatabase.Verify(db => db.SaveFaceAsync(It.IsAny<FaceData>(), It.IsAny<CancellationToken>()), Times.Once);
    }

    private byte[] LoadTestImage(string filename)
    {
        var path = Path.Combine("TestImages", filename);
        return File.ReadAllBytes(path);
    }

    private FaceData CreateTestFaceData(string name, byte[] imageBytes)
    {
        // 這裡需要實際的特徵向量，在真實測試中應從模型生成
        var featureVector = new float[512]; // ArcFace 通常是 512 維
        Array.Fill(featureVector, 0.1f); // 測試用的假數據
        
        return new FaceData
        {
            Id = Guid.NewGuid().ToString(),
            Name = name,
            FeatureVector = featureVector,
            BoundingBox = new Rectangle(100, 100, 200, 200),
            Quality = 0.95f,
            CreatedAt = DateTime.UtcNow
        };
    }
}
```

### 5.2. 整合測試詳細規劃

```csharp
[TestFixture]
[Category("Integration")]
public class FaceRecognitionIntegrationTests
{
    private FaceAiSharpService _service;
    private SQLiteFaceDatabase _database;
    private string _testDatabasePath;
    private IServiceProvider _serviceProvider;

    [OneTimeSetUp]
    public void OneTimeSetUp()
    {
        // 設定測試環境
        var services = new ServiceCollection();
        
        _testDatabasePath = Path.Combine(Path.GetTempPath(), $"test_faces_{Guid.NewGuid()}.db");
        
        services.AddSingleton<IFaceDatabase>(provider => 
            new SQLiteFaceDatabase($"Data Source={_testDatabasePath}", 
            provider.GetRequiredService<ILogger<SQLiteFaceDatabase>>()));
        
        services.AddSingleton<IFaceRecognitionService, FaceAiSharpService>();
        services.AddLogging(builder => builder.AddConsole());
        services.Configure<FaceAiSharpOptions>(options =>
        {
            options.DetectionModelPath = GetModelPath("scrfd_10g_bnkps.onnx");
            options.RecognitionModelPath = GetModelPath("arcfaceresnet100-8.onnx");
            options.EnableGpuAcceleration = false;
            options.RecognitionThreshold = 0.7f;
        });

        _serviceProvider = services.BuildServiceProvider();
        _service = (FaceAiSharpService)_serviceProvider.GetRequiredService<IFaceRecognitionService>();
        _database = (SQLiteFaceDatabase)_serviceProvider.GetRequiredService<IFaceDatabase>();
    }

    [Test]
    [Category("EndToEnd")]
    public async Task CompleteWorkflow_SaveAndRecognize_ShouldWork()
    {
        // Phase 1: 儲存已知人臉
        var trainingImage = LoadTestImage("person1_image1.jpg");
        var detectedFaces = await _service.DetectFacesAsync(trainingImage);
        
        Assert.That(detectedFaces.Count, Is.GreaterThan(0), "應該偵測到人臉進行訓練");
        
        var saveResult = await _service.SaveFaceAsync(detectedFaces[0], "Person1");
        Assert.That(saveResult, Is.True, "應該成功儲存訓練人臉");

        // Phase 2: 測試同一人的不同照片
        var testImage = LoadTestImage("person1_image2.jpg");
        var recognitionResult = await _service.RecognizeFaceAsync(testImage);
        
        Assert.That(recognitionResult.DetectedFaces.Count, Is.GreaterThan(0));
        Assert.That(recognitionResult.DetectedFaces[0].Name, Is.EqualTo("Person1"));
        Assert.That(recognitionResult.DetectedFaces[0].Confidence, Is.GreaterThan(0.7f));

        // Phase 3: 測試不同人的照片
        var strangerImage = LoadTestImage("person2_image1.jpg");
        var strangerResult = await _service.RecognizeFaceAsync(strangerImage);
        
        Assert.That(strangerResult.DetectedFaces.Count, Is.GreaterThan(0));
        Assert.That(strangerResult.DetectedFaces[0].IsUnknown, Is.True);
    }

    [Test]
    [Category("Database")]
    public async Task DatabaseOperations_CRUDOperations_ShouldWork()
    {
        // Create
        var faceData = new FaceData
        {
            Name = "TestPerson",
            FeatureVector = GenerateRandomFeatureVector(),
            BoundingBox = new Rectangle(50, 50, 100, 100),
            Quality = 0.9f
        };

        var saveResult = await _database.SaveFaceAsync(faceData);
        Assert.That(saveResult, Is.True);

        // Read
        var retrievedFace = await _database.GetFaceByNameAsync("TestPerson");
        Assert.That(retrievedFace, Is.Not.Null);
        Assert.That(retrievedFace.Name, Is.EqualTo("TestPerson"));

        // Update
        retrievedFace.Quality = 0.95f;
        var updateResult = await _database.UpdateFaceAsync(retrievedFace);
        Assert.That(updateResult, Is.True);

        // Delete
        var deleteResult = await _database.DeleteFaceAsync("TestPerson");
        Assert.That(deleteResult, Is.True);

        var deletedFace = await _database.GetFaceByNameAsync("TestPerson");
        Assert.That(deletedFace, Is.Null);
    }

    [Test]
    [Category("Performance")]
    public async Task PerformanceTest_ProcessMultipleFaces_ShouldMeetRequirements()
    {
        // 測試處理多張人臉的性能
        var testImages = new[]
        {
            LoadTestImage("group_photo_1.jpg"),
            LoadTestImage("group_photo_2.jpg"),
            LoadTestImage("group_photo_3.jpg")
        };

        var stopwatch = Stopwatch.StartNew();
        var totalFaces = 0;

        foreach (var image in testImages)
        {
            var result = await _service.DetectFacesAsync(image);
            totalFaces += result.Count;
        }

        stopwatch.Stop();

        Assert.That(totalFaces, Is.GreaterThan(0));
        Assert.That(stopwatch.ElapsedMilliseconds / totalFaces, Is.LessThan(2000), 
                   "每張人臉處理時間應小於 2 秒");
    }
}
```

### 5.3. UI 自動化測試

```csharp
[TestFixture]
[Category("UI")]
public class FaceRecognitionPageUITests
{
    private AppiumDriver<WindowsElement> _driver;

    [SetUp]
    public void SetUp()
    {
        var options = new AppiumOptions();
        options.AddAdditionalCapability("app", "MapLocationApp.exe");
        options.AddAdditionalCapability("deviceName", "WindowsPC");
        
        _driver = new WindowsDriver<WindowsElement>(
            new Uri("http://127.0.0.1:4723"), options);
    }

    [Test]
    [Category("CameraTest")]
    public async Task CameraPreview_ShouldStartSuccessfully()
    {
        // 導航到人臉辨識頁面
        var faceRecognitionTab = _driver.FindElementByName("人臉辨識");
        faceRecognitionTab.Click();

        await Task.Delay(2000); // 等待頁面載入

        // 驗證相機預覽是否啟動
        var cameraView = _driver.FindElementByAccessibilityId("CameraView");
        Assert.That(cameraView.Displayed, Is.True);

        // 驗證控制按鈕是否可見
        var captureButton = _driver.FindElementByAccessibilityId("CaptureButton");
        Assert.That(captureButton.Enabled, Is.True);
    }

    [Test]
    [Category("FaceDetection")]
    public async Task FaceDetection_WithFaceVisible_ShouldShowBoundingBox()
    {
        // 模擬有人臉出現在相機前
        var faceRecognitionTab = _driver.FindElementByName("人臉辨識");
        faceRecognitionTab.Click();

        await Task.Delay(3000); // 等待人臉偵測

        // 驗證是否顯示人臉框
        var faceOverlay = _driver.FindElementsByClassName("FaceBoundingBox");
        Assert.That(faceOverlay.Count, Is.GreaterThan(0));
    }

    [Test]
    [Category("FaceSave")]
    public async Task SaveFace_ShouldShowNameInputDialog()
    {
        var faceRecognitionTab = _driver.FindElementByName("人臉辨識");
        faceRecognitionTab.Click();

        await Task.Delay(2000);

        // 點擊儲存人臉按鈕
        var saveButton = _driver.FindElementByAccessibilityId("SaveFaceButton");
        saveButton.Click();

        // 驗證名稱輸入對話框
        var nameDialog = _driver.FindElementByAccessibilityId("NameInputDialog");
        Assert.That(nameDialog.Displayed, Is.True);

        var nameTextBox = _driver.FindElementByAccessibilityId("NameTextBox");
        nameTextBox.SendKeys("測試人員");

        var confirmButton = _driver.FindElementByAccessibilityId("ConfirmButton");
        confirmButton.Click();

        await Task.Delay(1000);

        // 驗證成功訊息
        var successMessage = _driver.FindElementByAccessibilityId("SuccessMessage");
        Assert.That(successMessage.Text, Does.Contain("儲存成功"));
    }

    [TearDown]
    public void TearDown()
    {
        _driver?.Quit();
    }
}
```

### 5.4. 效能基準測試

```csharp
[TestFixture]
[Category("Benchmark")]
public class FaceRecognitionBenchmarkTests
{
    private FaceAiSharpService _service;
    private BenchmarkConfiguration _config;

    [SetUp]
    public void SetUp()
    {
        _config = new BenchmarkConfiguration
        {
            TestImageSizes = new[] { 640, 1280, 1920 },
            FaceCountsToTest = new[] { 1, 3, 5, 10 },
            IterationsPerTest = 10
        };
    }

    [Test, Performance]
    public async Task Benchmark_FaceDetection_VariousImageSizes()
    {
        var results = new List<BenchmarkResult>();

        foreach (var imageSize in _config.TestImageSizes)
        {
            var testImage = GenerateTestImageWithFaces(imageSize, imageSize, 3);
            var times = new List<TimeSpan>();

            for (int i = 0; i < _config.IterationsPerTest; i++)
            {
                var stopwatch = Stopwatch.StartNew();
                await _service.DetectFacesAsync(testImage);
                stopwatch.Stop();
                times.Add(stopwatch.Elapsed);
            }

            results.Add(new BenchmarkResult
            {
                TestName = $"Detection_{imageSize}px",
                AverageTime = TimeSpan.FromMilliseconds(times.Average(t => t.TotalMilliseconds)),
                MinTime = times.Min(),
                MaxTime = times.Max(),
                StandardDeviation = CalculateStandardDeviation(times)
            });
        }

        // 輸出基準測試報告
        GenerateBenchmarkReport(results);

        // 驗證效能需求
        foreach (var result in results)
        {
            Assert.That(result.AverageTime.TotalSeconds, Is.LessThan(5.0), 
                       $"{result.TestName} 平均處理時間應小於 5 秒");
        }
    }

    [Test, Performance]
    public async Task Benchmark_FaceRecognition_DatabaseSize()
    {
        var results = new List<BenchmarkResult>();
        var databaseSizes = new[] { 10, 50, 100, 500 };

        foreach (var dbSize in databaseSizes)
        {
            // 預載指定數量的人臉到資料庫
            await PopulateDatabaseWithFaces(dbSize);

            var testImage = LoadTestImage("recognition_test.jpg");
            var times = new List<TimeSpan>();

            for (int i = 0; i < _config.IterationsPerTest; i++)
            {
                var stopwatch = Stopwatch.StartNew();
                await _service.RecognizeFaceAsync(testImage);
                stopwatch.Stop();
                times.Add(stopwatch.Elapsed);
            }

            results.Add(new BenchmarkResult
            {
                TestName = $"Recognition_DB{dbSize}",
                AverageTime = TimeSpan.FromMilliseconds(times.Average(t => t.TotalMilliseconds)),
                MinTime = times.Min(),
                MaxTime = times.Max()
            });

            // 清理資料庫
            await ClearDatabase();
        }

        GenerateBenchmarkReport(results);
    }

    [Test, Performance]
    public async Task Benchmark_ConcurrentRequests()
    {
        var testImage = LoadTestImage("concurrent_test.jpg");
        var concurrencyLevels = new[] { 1, 2, 4, 8, 16 };
        var results = new List<BenchmarkResult>();

        foreach (var concurrency in concurrencyLevels)
        {
            var stopwatch = Stopwatch.StartNew();
            var tasks = new List<Task>();

            for (int i = 0; i < concurrency; i++)
            {
                tasks.Add(_service.DetectFacesAsync(testImage));
            }

            await Task.WhenAll(tasks);
            stopwatch.Stop();

            results.Add(new BenchmarkResult
            {
                TestName = $"Concurrent_{concurrency}",
                AverageTime = TimeSpan.FromMilliseconds(stopwatch.ElapsedMilliseconds / (double)concurrency),
                TotalTime = stopwatch.Elapsed
            });
        }

        GenerateBenchmarkReport(results);
    }
}

public class BenchmarkResult
{
    public string TestName { get; set; } = string.Empty;
    public TimeSpan AverageTime { get; set; }
    public TimeSpan MinTime { get; set; }
    public TimeSpan MaxTime { get; set; }
    public TimeSpan TotalTime { get; set; }
    public double StandardDeviation { get; set; }
}
```

### 5.5. 平台相容性測試矩陣

| 測試項目 | Windows 10 | Windows 11 | macOS Intel | macOS M1 | Android 12+ | iOS 15+ |
|---------|------------|------------|-------------|----------|-------------|----------|
| FaceAiSharp 初始化 | ✅ | ✅ | ✅ | ✅ | ⚠️ 備用 | ⚠️ 備用 |
| ONNX CPU 推理 | ✅ | ✅ | ✅ | ✅ | ❌ | ❌ |
| GPU 加速 | ✅ CUDA | ✅ CUDA | ❌ | ❌ | ❌ | ❌ |
| 相機整合 | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |
| 即時處理 | ✅ | ✅ | ✅ | ⚠️ 性能測試 | ⚠️ ML Kit | ⚠️ Vision |
| 資料庫操作 | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |

### 5.6. 測試數據集要求

**基本測試圖片:**
- `single_face_front.jpg` - 正面單人照
- `single_face_profile.jpg` - 側臉照
- `multiple_faces.jpg` - 多人合照
- `no_faces.jpg` - 無人臉圖片
- `low_light.jpg` - 低光照片
- `high_contrast.jpg` - 高對比照片
- `blurred_face.jpg` - 模糊人臉
- `small_face.jpg` - 小尺寸人臉
- `masked_face.jpg` - 戴口罩人臉
- `glasses_face.jpg` - 戴眼鏡人臉

**效能測試圖片:**
- 各種解析度: 480p, 720p, 1080p, 4K
- 不同人臉數量: 1-20 張人臉
- 不同年齡群組: 兒童、青年、中年、老年
- 不同種族背景的測試樣本

**準確度測試集:**
- 最少 100 個不同身份的人臉
- 每個身份至少 5 張不同角度/光照的照片
- Ground Truth 標註檔案

### 5.7. 測試自動化 CI/CD 流程

```yaml
# Azure DevOps Pipeline
trigger:
  branches:
    include:
    - main
    - develop

pool:
  vmImage: 'windows-latest'

stages:
- stage: UnitTests
  jobs:
  - job: RunUnitTests
    steps:
    - task: DotNetCoreCLI@2
      displayName: '執行單元測試'
      inputs:
        command: 'test'
        projects: '**/*Tests.csproj'
        arguments: '--configuration Release --collect:"XPlat Code Coverage" --logger trx --results-directory $(Agent.TempDirectory)'

- stage: IntegrationTests
  dependsOn: UnitTests
  jobs:
  - job: RunIntegrationTests
    steps:
    - task: DownloadSecureFile@1
      displayName: '下載測試模型'
      inputs:
        secureFile: 'test-models.zip'
    - task: ExtractFiles@1
      inputs:
        archiveFilePatterns: '$(Agent.TempDirectory)/test-models.zip'
        destinationFolder: '$(Build.SourcesDirectory)/TestModels'
    - task: DotNetCoreCLI@2
      displayName: '執行整合測試'
      inputs:
        command: 'test'
        projects: '**/*IntegrationTests.csproj'
        arguments: '--configuration Release --logger trx'

- stage: PerformanceTests
  dependsOn: IntegrationTests
  jobs:
  - job: RunBenchmarks
    steps:
    - task: DotNetCoreCLI@2
      displayName: '執行效能基準測試'
      inputs:
        command: 'run'
        projects: '**/BenchmarkTests.csproj'
        arguments: '--configuration Release -- --exporters json'
    - task: PublishTestResults@2
      displayName: '發布效能測試結果'
      inputs:
        testResultsFormat: 'JUnit'
        testResultsFiles: '**/benchmark-results.xml'
```

## FaceAiSharp 專案開發時程

| 階段 | 預估時間 | 主要工作項目 | FaceAiSharp 特定任務 |
|-----|---------|-------------|-------------------|
| Phase 1 | 2-3 天 | 基礎架構設置 | FaceAiSharp.Bundle 安裝與初始化 |
| Phase 2 | 4-5 天 | UI 與相機整合 | ImageSharp 與 CameraView 整合 |
| Phase 3 | 6-8 天 | 核心功能實作 | ONNX 模型載入與推理優化 |
| Phase 4 | 2-3 天 | 資料持久化 | 特徵向量儲存與加密 |
| Phase 5 | 3-4 天 | 測試與優化 | 性能調整與硬體加速 |
| Phase 6 | 2-3 天 | 移動平台適配 | ML Kit/Vision 備用方案測試 |
| **總計** | **19-26 天** | **FaceAiSharp 優先方案** | **比傳統方案減少 25-30%** |

## 風險評估

### 高風險項目
- 移動平台的人臉辨識準確度可能低於桌面平台
- 不同裝置的相機 API 差異可能導致相容性問題
- 效能優化挑戰，特別是低階裝置

### 中風險項目
- NuGet 套件的長期維護支援
- 不同平台的 UI 一致性挑戰
- 資料遷移和向後相容性

### 低風險項目
- 基本的相機存取功能
- 本地資料儲存
- 基礎 UI 實作

## FaceAiSharp 技術方案總結

### 核心優勢
1. **現代技術棧:** 基於 ImageSharp + ONNX Runtime 的最新架構
2. **統一 API:** 一個套件支持多種人臉功能
3. **MIT 授權:** 完全商業友好的開源授權
4. **效能優異:** ONNX Runtime 支持硬體加速
5. **安全尚佳:** 完全本地化處理，無數據外洩

### 實施建議
- **MVP 策略:** 優先實作 Windows/macOS 桌面版本
- **技術分層:** FaceAiSharp 為主，ML Kit/Vision 為輔
- **性能目標:** 利用 ONNX 優化達到即時處理效能
- **部署策略:** Bundle 套件簡化部署複雜度

## 6. 詳細實作指導原則

### 6.1. 專案結構建議

```
MapLocationApp/
├── Services/
│   ├── FaceRecognition/
│   │   ├── IFaceRecognitionService.cs          # 主要服務介面
│   │   ├── FaceAiSharpService.cs               # FaceAiSharp 實作
│   │   ├── Models/                             # 資料模型
│   │   │   ├── FaceData.cs
│   │   │   ├── RecognitionResult.cs
│   │   │   ├── DetectedFace.cs
│   │   │   └── FacialLandmarks.cs
│   │   ├── Database/                           # 資料庫層
│   │   │   ├── IFaceDatabase.cs
│   │   │   ├── SQLiteFaceDatabase.cs
│   │   │   └── Migrations/
│   │   ├── Configuration/                      # 配置
│   │   │   ├── FaceAiSharpOptions.cs
│   │   │   └── DatabaseOptions.cs
│   │   ├── Exceptions/                         # 自定義異常
│   │   │   ├── FaceRecognitionException.cs
│   │   │   ├── ModelNotLoadedException.cs
│   │   │   └── DatabaseException.cs
│   │   └── Platform/                           # 平台特定實作
│   │       ├── Android/
│   │       │   └── AndroidMLKitService.cs
│   │       └── iOS/
│   │           └── iOSVisionService.cs
│   └── Camera/
│       ├── ICameraService.cs
│       └── CameraService.cs
├── Views/
│   ├── FaceRecognitionPage.xaml
│   └── FaceRecognitionPage.xaml.cs
├── ViewModels/
│   └── FaceRecognitionViewModel.cs
├── Resources/
│   └── Models/                                 # ONNX 模型檔案
│       ├── scrfd_10g_bnkps.onnx
│       ├── arcfaceresnet100-8.onnx
│       └── open-closed-eye-0001.onnx
└── Tests/
    ├── UnitTests/
    ├── IntegrationTests/
    ├── BenchmarkTests/
    └── TestData/
        └── Images/
```

### 6.2. 初始化檢查清單

**Phase 1: 環境設置**
- [ ] 確認 .NET 9 SDK 安裝
- [ ] 安裝 Visual Studio 2024 或 VS Code
- [ ] 確認 Git 版本控制設置
- [ ] 設定 NuGet 套件來源

**Phase 2: 套件安裝**
```bash
# 核心套件
dotnet add package FaceAiSharp.Bundle --version 0.5.23
dotnet add package Microsoft.Extensions.DependencyInjection --version 8.0.0
dotnet add package Microsoft.Extensions.Logging --version 8.0.0
dotnet add package Microsoft.Extensions.Options --version 8.0.0

# 資料庫
dotnet add package Microsoft.Data.Sqlite --version 8.0.0
dotnet add package sqlite-net-pcl --version 1.9.172

# 相機與影像處理
dotnet add package CommunityToolkit.Maui.Camera --version 1.0.4
dotnet add package SixLabors.ImageSharp --version 3.1.5

# 測試套件
dotnet add package NUnit --version 4.0.1
dotnet add package Moq --version 4.20.70
dotnet add package BenchmarkDotNet --version 0.13.12
```

**Phase 3: 模型準備**
- [ ] 下載 SCRFD 人臉偵測模型
- [ ] 下載 ArcFace 人臉識別模型  
- [ ] 下載眼睛狀態檢測模型（可選）
- [ ] 驗證模型檔案完整性
- [ ] 設定模型檔案路徑配置

### 6.3. 依賴注入配置

```csharp
// MauiProgram.cs
public static class MauiProgram
{
    public static MauiApp CreateMauiApp()
    {
        var builder = MauiApp.CreateBuilder();
        builder
            .UseMauiApp<App>()
            .UseMauiCommunityToolkitCamera()
            .ConfigureFonts(fonts =>
            {
                fonts.AddFont("OpenSans-Regular.ttf", "OpenSansRegular");
            });

        // 配置服務
        ConfigureFaceRecognitionServices(builder.Services);
        
        return builder.Build();
    }

    private static void ConfigureFaceRecognitionServices(IServiceCollection services)
    {
        // 配置選項
        services.Configure<FaceAiSharpOptions>(options =>
        {
            options.DetectionModelPath = "Resources/Models/scrfd_10g_bnkps.onnx";
            options.RecognitionModelPath = "Resources/Models/arcfaceresnet100-8.onnx";
            options.EyeStateModelPath = "Resources/Models/open-closed-eye-0001.onnx";
            options.EnableGpuAcceleration = true;
            options.EnableEyeStateDetection = true;
            options.RecognitionThreshold = 0.7f;
            options.MaxConcurrentOperations = Environment.ProcessorCount;
        });

        services.Configure<DatabaseOptions>(options =>
        {
            var appDataPath = FileSystem.AppDataDirectory;
            options.ConnectionString = $"Data Source={Path.Combine(appDataPath, "faces.db")}";
            options.EnableEncryption = true;
        });

        // 註冊服務
        services.AddSingleton<IFaceDatabase, SQLiteFaceDatabase>();
        services.AddSingleton<IFaceRecognitionService, FaceAiSharpService>();
        services.AddSingleton<ICameraService, CameraService>();
        
        // 註冊 ViewModels
        services.AddTransient<FaceRecognitionViewModel>();
        
        // 註冊 Views
        services.AddTransient<FaceRecognitionPage>();

        // 配置日誌
        services.AddLogging(configure =>
        {
#if DEBUG
            configure.AddDebug();
#endif
            configure.AddConsole();
            configure.SetMinimumLevel(LogLevel.Information);
        });
    }
}
```

### 6.4. 錯誤處理完整策略

```csharp
// 自定義異常類型
public class FaceRecognitionException : Exception
{
    public ErrorCode ErrorCode { get; }
    public Dictionary<string, object> Context { get; }

    public FaceRecognitionException(ErrorCode errorCode, string message, Exception? innerException = null)
        : base(message, innerException)
    {
        ErrorCode = errorCode;
        Context = new Dictionary<string, object>();
    }
}

public enum ErrorCode
{
    // 初始化錯誤
    ModelNotFound = 1001,
    ModelLoadFailed = 1002,
    OnnxRuntimeError = 1003,
    
    // 輸入錯誤
    InvalidImageData = 2001,
    ImageTooLarge = 2002,
    UnsupportedFormat = 2003,
    
    // 處理錯誤
    DetectionFailed = 3001,
    RecognitionFailed = 3002,
    FeatureExtractionFailed = 3003,
    
    // 資料庫錯誤
    DatabaseConnectionFailed = 4001,
    DatabaseWriteFailed = 4002,
    DuplicateFaceName = 4003,
    
    // 相機錯誤
    CameraNotAvailable = 5001,
    CameraPermissionDenied = 5002,
    CameraInitializationFailed = 5003,
    
    // 系統錯誤
    OutOfMemory = 6001,
    ConcurrencyLimitExceeded = 6002,
    ServiceNotInitialized = 6003
}

// 全局錯誤處理器
public class GlobalErrorHandler
{
    private readonly ILogger<GlobalErrorHandler> _logger;

    public GlobalErrorHandler(ILogger<GlobalErrorHandler> logger)
    {
        _logger = logger;
    }

    public async Task<ErrorResponse> HandleExceptionAsync(Exception exception)
    {
        return exception switch
        {
            FaceRecognitionException faceEx => await HandleFaceRecognitionException(faceEx),
            OutOfMemoryException memEx => await HandleMemoryException(memEx),
            UnauthorizedAccessException authEx => await HandleAuthorizationException(authEx),
            TimeoutException timeoutEx => await HandleTimeoutException(timeoutEx),
            _ => await HandleGenericException(exception)
        };
    }

    private async Task<ErrorResponse> HandleFaceRecognitionException(FaceRecognitionException exception)
    {
        var response = new ErrorResponse
        {
            ErrorCode = exception.ErrorCode,
            Message = GetUserFriendlyMessage(exception.ErrorCode),
            TechnicalDetails = exception.Message,
            Timestamp = DateTime.UtcNow,
            Context = exception.Context
        };

        // 根據錯誤類型決定日誌級別
        var logLevel = GetLogLevel(exception.ErrorCode);
        _logger.Log(logLevel, exception, "Face recognition error: {ErrorCode}", exception.ErrorCode);

        // 特定錯誤的額外處理
        switch (exception.ErrorCode)
        {
            case ErrorCode.ModelNotFound:
                response.SuggestedActions = new[] { "檢查模型檔案是否存在", "重新下載模型檔案", "聯繫技術支援" };
                break;
            case ErrorCode.OutOfMemory:
                response.SuggestedActions = new[] { "關閉其他應用程式", "重新啟動應用程式", "降低影像解析度" };
                break;
            case ErrorCode.CameraPermissionDenied:
                response.SuggestedActions = new[] { "檢查應用程式權限設定", "重新授予相機權限", "重新啟動應用程式" };
                break;
        }

        return response;
    }

    private string GetUserFriendlyMessage(ErrorCode errorCode)
    {
        return errorCode switch
        {
            ErrorCode.ModelNotFound => "人臉識別模型檔案遺失，請重新安裝應用程式",
            ErrorCode.CameraNotAvailable => "無法存取相機，請確認相機未被其他應用程式使用",
            ErrorCode.InvalidImageData => "影像檔案格式不支援或已損壞",
            ErrorCode.DatabaseConnectionFailed => "資料庫連接失敗，請重新啟動應用程式",
            ErrorCode.OutOfMemory => "記憶體不足，請關閉其他應用程式後重試",
            _ => "發生未知錯誤，請聯繫技術支援"
        };
    }
}

public class ErrorResponse
{
    public ErrorCode ErrorCode { get; set; }
    public string Message { get; set; } = string.Empty;
    public string TechnicalDetails { get; set; } = string.Empty;
    public DateTime Timestamp { get; set; }
    public Dictionary<string, object> Context { get; set; } = new();
    public string[] SuggestedActions { get; set; } = Array.Empty<string>();
}
```

### 6.5. 效能監控與基準測試

```csharp
// 效能監控服務
public class PerformanceMonitor
{
    private readonly ILogger<PerformanceMonitor> _logger;
    private readonly ConcurrentDictionary<string, PerformanceMetric> _metrics = new();

    public PerformanceMonitor(ILogger<PerformanceMonitor> logger)
    {
        _logger = logger;
    }

    public IDisposable StartOperation(string operationName)
    {
        return new OperationTimer(operationName, this);
    }

    public void RecordOperation(string operationName, TimeSpan duration, bool success = true)
    {
        _metrics.AddOrUpdate(operationName, 
            new PerformanceMetric(operationName),
            (key, existing) =>
            {
                existing.RecordOperation(duration, success);
                return existing;
            });

        // 記錄慢操作
        if (duration.TotalSeconds > 5.0)
        {
            _logger.LogWarning("Slow operation detected: {Operation} took {Duration}ms", 
                operationName, duration.TotalMilliseconds);
        }
    }

    public PerformanceReport GetReport()
    {
        return new PerformanceReport
        {
            Metrics = _metrics.Values.ToList(),
            GeneratedAt = DateTime.UtcNow
        };
    }

    private class OperationTimer : IDisposable
    {
        private readonly string _operationName;
        private readonly PerformanceMonitor _monitor;
        private readonly Stopwatch _stopwatch;
        private bool _disposed;

        public OperationTimer(string operationName, PerformanceMonitor monitor)
        {
            _operationName = operationName;
            _monitor = monitor;
            _stopwatch = Stopwatch.StartNew();
        }

        public void Dispose()
        {
            if (!_disposed)
            {
                _stopwatch.Stop();
                _monitor.RecordOperation(_operationName, _stopwatch.Elapsed);
                _disposed = true;
            }
        }
    }
}

public class PerformanceMetric
{
    public string OperationName { get; }
    public int TotalOperations { get; private set; }
    public int SuccessfulOperations { get; private set; }
    public TimeSpan TotalTime { get; private set; }
    public TimeSpan MinTime { get; private set; } = TimeSpan.MaxValue;
    public TimeSpan MaxTime { get; private set; }
    public List<TimeSpan> RecentOperations { get; } = new();

    public PerformanceMetric(string operationName)
    {
        OperationName = operationName;
    }

    public void RecordOperation(TimeSpan duration, bool success)
    {
        lock (this)
        {
            TotalOperations++;
            if (success) SuccessfulOperations++;
            
            TotalTime += duration;
            if (duration < MinTime) MinTime = duration;
            if (duration > MaxTime) MaxTime = duration;

            RecentOperations.Add(duration);
            if (RecentOperations.Count > 100) // 保留最近 100 次操作
                RecentOperations.RemoveAt(0);
        }
    }

    public double AverageTimeMs => TotalOperations > 0 ? TotalTime.TotalMilliseconds / TotalOperations : 0;
    public double SuccessRate => TotalOperations > 0 ? (double)SuccessfulOperations / TotalOperations : 0;
}

// 基準測試要求
public class BenchmarkRequirements
{
    public static readonly BenchmarkTarget[] Targets = 
    {
        new("人臉偵測 - 單張人臉", maxTimeMs: 1000, targetAccuracy: 0.95),
        new("人臉偵測 - 多張人臉(5張)", maxTimeMs: 2000, targetAccuracy: 0.90),
        new("人臉辨識 - 小型資料庫(<50人)", maxTimeMs: 500, targetAccuracy: 0.95),
        new("人臉辨識 - 中型資料庫(50-200人)", maxTimeMs: 1000, targetAccuracy: 0.93),
        new("人臉辨識 - 大型資料庫(200+人)", maxTimeMs: 2000, targetAccuracy: 0.90),
        new("相機預覽啟動", maxTimeMs: 3000, targetAccuracy: 0.98),
        new("資料庫讀取操作", maxTimeMs: 100, targetAccuracy: 0.99),
        new("資料庫寫入操作", maxTimeMs: 200, targetAccuracy: 0.99)
    };
}

public record BenchmarkTarget(string Name, int MaxTimeMs, double TargetAccuracy);
```

### 6.6. 部署與維護指南

**生產環境檢查清單:**
- [ ] 所有 ONNX 模型檔案已包含在部署包中
- [ ] 資料庫連接字串已設定加密
- [ ] 日誌等級設定為 Information 或 Warning
- [ ] 效能監控已啟用
- [ ] 異常處理和用戶反饋機制已實作
- [ ] 記憶體使用情況監控已設置
- [ ] 相機權限處理已正確實作

**維護計劃:**
1. **每週檢查:**
   - 效能指標回顧
   - 錯誤日誌分析
   - 記憶體使用情況

2. **每月檢查:**
   - 模型準確度評估
   - 新版本 FaceAiSharp 套件檢查
   - 用戶反饋整理

3. **每季檢查:**
   - 完整的效能基準測試
   - 資料庫效能優化
   - 備份和恢復測試

### 6.7. AI 開發助手使用指導

**給 AI 的具體指令模板:**

```markdown
使用這個技術文件開發 MapLocationApp 人臉辨識功能時，請遵循以下原則：

1. **嚴格遵循架構:** 使用文件中定義的介面和資料模型
2. **錯誤處理:** 每個公開方法都必須包含完整的錯誤處理
3. **效能考慮:** 所有 async 方法都要支援 CancellationToken
4. **測試覆蓋:** 每個新功能都要有對應的單元測試
5. **日誌記錄:** 重要操作都要有適當的日誌記錄
6. **資源管理:** 實作 IDisposable 介面管理非託管資源

實作新功能時的步驟：
1. 先寫介面定義
2. 實作核心邏輯
3. 加入錯誤處理
4. 撰寫單元測試
5. 撰寫整合測試
6. 更新文件
```

這個 FaceAiSharp 為中心的方案將為 MapLocationApp 提供最現代化、最可靠的人臉識別功能。文件中包含的所有程式碼範例、測試案例、錯誤處理策略和效能基準都是為了確保 AI 開發助手能夠完整理解並正確實作這個複雜的系統。

---

**文件版本:** 2.0  
**建立日期:** 2025-08-30  
**最後更新:** 2025-08-30  
**作者:** Claude Code Assistant  
**文件類型:** AI 開發指導文件  
**適用對象:** AI 程式開發助手、軟體工程師  
**技術棧:** .NET 9, MAUI, FaceAiSharp, ONNX Runtime